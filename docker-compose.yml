
services:
  # PostgreSQL Database
  # Central database for episodes, transcripts, summaries, and all state management
  postgres:
    image: postgres:15-alpine
    container_name: podcast-postgres
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-podcast_user}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-podcast_password}
      - POSTGRES_DB=${POSTGRES_DB:-podcast_transcriber}
    networks:
      - podcast-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-podcast_user} -d ${POSTGRES_DB:-podcast_transcriber}"]
      interval: 5s
      timeout: 3s
      retries: 5

  # Qdrant Vector Database
  # Used by RAG service for storing transcript embeddings
  qdrant:
    image: qdrant/qdrant:latest
    container_name: podcast-qdrant
    ports:
      - "6333:6333"  # REST API
      - "6334:6334"  # gRPC API
    volumes:
      - qdrant_storage:/qdrant/storage
    environment:
      - QDRANT_ALLOW_RECOVERY_MODE=true
    networks:
      - podcast-network
    restart: unless-stopped

  # Redis Message Broker
  # Used for event-driven communication between services
  redis:
    image: redis:7-alpine
    container_name: podcast-redis
    ports:
      - "6379:6379"  # Redis port
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes  # Enable persistence
    networks:
      - podcast-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5

  # Transcription Worker (GPU-enabled)
  # Runs continuously polling Redis for transcription jobs
  # Uses Redis queue architecture - API enqueues jobs, worker processes them
  transcription-worker:
    build:
      context: .
      dockerfile: Dockerfile.transcription-worker
    container_name: podcast-transcription-worker
    runtime: nvidia  # Requires nvidia-container-toolkit
    environment:
      # GPU configuration
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=0
      # Service configuration
      - REDIS_URL=redis://redis:6379
      - DATABASE_URL=${DATABASE_URL}
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
      - DEVICE=cuda
      - COMPUTE_TYPE=int8
      - BATCH_SIZE=4
      - WHISPER_MODEL=large-v2
      # Python configuration for logging visibility
      - PYTHONUNBUFFERED=1
    volumes:
      # Shared directories for config and logging only
      - ./shared/config:/app/shared/config
      - ./shared/logs:/app/shared/logs
      - ./shared:/app/shared  # Shared library for event bus and database
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - podcast-network
    # Run continuously, restart if crashes
    restart: unless-stopped
    # Run daemon mode instead of one-shot CLI
    command: python src/worker_daemon.py
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # RAG Service (FastAPI Backend)
  # Provides semantic search and Q&A over transcripts using Ollama
  rag-service:
    build:
      context: .
      dockerfile: rag-service/Dockerfile
    container_name: podcast-rag-service
    ports:
      - "${RAG_API_PORT:-8000}:8000"
    volumes:
      # Mount shared directories for events module and logs
      - ./shared:/app/shared  # Shared library for event bus and database
      - ./shared/logs:/app/shared/logs  # Logs
    environment:
      # Ollama runs on host, accessed via host network
      - OLLAMA_API_URL=${OLLAMA_API_URL:-http://host.docker.internal:11434}
      - OLLAMA_CHAT_MODEL=${OLLAMA_CHAT_MODEL:-qwen3:rag}
      - OLLAMA_EMBED_MODEL=${OLLAMA_EMBED_MODEL:-nomic-embed-text}
      - QDRANT_URL=http://qdrant:6333  # Use Docker network DNS
      - QDRANT_COLLECTION_NAME=${QDRANT_COLLECTION_NAME:-podcast_transcripts}
      - EMBEDDING_DIMENSION=${EMBEDDING_DIMENSION:-768}
      - CHUNK_SIZE=${CHUNK_SIZE:-500}
      - CHUNK_OVERLAP=${CHUNK_OVERLAP:-100}
      - TOP_K_RESULTS=${TOP_K_RESULTS:-5}
      - SIMILARITY_THRESHOLD=${SIMILARITY_THRESHOLD:-0.7}
      - RAG_FRONTEND_URL=${RAG_FRONTEND_URL:-http://localhost:3000}
      - REDIS_URL=${REDIS_URL:-redis://redis:6379}  # Redis for events
      - DATABASE_URL=${DATABASE_URL}  # PostgreSQL for transcripts
      - PYTHONUNBUFFERED=1
      - PYTHONPATH=/app/shared:/app/src:/app  # Include /app/shared FIRST to override installed package
    depends_on:
      postgres:
        condition: service_healthy
      qdrant:
        condition: service_started
      redis:
        condition: service_healthy
    networks:
      - podcast-network
    extra_hosts:
      - "host.docker.internal:host-gateway"  # Enable access to host machine services
    restart: unless-stopped

  # Summarization Service (FastAPI Backend)
  # Generates summaries from transcripts using Gemini API
  summarization-service:
    build:
      context: .
      dockerfile: summarization-service/Dockerfile
    container_name: podcast-summarization-service
    ports:
      - "${SUMMARIZATION_API_PORT:-8002}:8002"
    volumes:
      # Mount shared directories for events module and logs
      - ./shared/logs:/app/shared/logs  # Logs
      - ./shared:/app/shared  # Shared library for event bus and database
    secrets:
      - gemini_api_key
    environment:
      # Use Docker Secret for API key (more secure than env vars)
      - GEMINI_API_KEY_FILE=/run/secrets/gemini_api_key
      - SUMMARIZATION_MODEL=${SUMMARIZATION_MODEL:-gemini-2.5-flash-lite}
      - SUMMARIZATION_API_PORT=${SUMMARIZATION_API_PORT:-8002}
      - SUMMARIZATION_FRONTEND_URL=${SUMMARIZATION_FRONTEND_URL:-http://localhost:3000}
      - REDIS_URL=${REDIS_URL:-redis://redis:6379}  # Redis for events
      - DATABASE_URL=${DATABASE_URL}  # PostgreSQL for summaries
      - PYTHONUNBUFFERED=1
      - PYTHONPATH=/app/src:/app/shared  # Include shared for event bus imports
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - podcast-network
    restart: unless-stopped
    command: uvicorn src.main:app --host 0.0.0.0 --port 8002

  # Transcription API (FastAPI Backend)
  # Provides REST API for managing podcast feeds and transcription queue
  transcription-api:
    build:
      context: .
      dockerfile: transcription-service/Dockerfile.api
    container_name: podcast-transcription-api
    ports:
      - "${TRANSCRIPTION_API_PORT:-8001}:8001"
    volumes:
      # Mount shared directories for configs and logs
      - ./shared/config:/app/shared/config  # Read-write for configs
      - ./shared/logs:/app/shared/logs  # Logs
      - ./shared:/app/shared  # Shared library for database
    environment:
      - DATABASE_URL=${DATABASE_URL}  # PostgreSQL for episodes
      - REDIS_URL=${REDIS_URL:-redis://redis:6379}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - podcast-network
    restart: unless-stopped

  # Frontend (React)
  # User interface for searching and browsing transcripts
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        - VITE_USE_MOCK_API=false
        - VITE_RAG_API_URL=http://localhost:${RAG_API_PORT:-8000}
        - VITE_TRANSCRIPTION_API_URL=http://localhost:${TRANSCRIPTION_API_PORT:-8001}
        - VITE_SUMMARIZATION_API_URL=http://localhost:${SUMMARIZATION_API_PORT:-8002}
    container_name: podcast-frontend
    ports:
      - "${FRONTEND_PORT:-3000}:3000"
    depends_on:
      - rag-service
      - transcription-api
      - summarization-service
    networks:
      - podcast-network
    restart: unless-stopped

volumes:
  # Persistent storage for PostgreSQL database
  postgres_data:
    driver: local
  
  # Persistent storage for Qdrant vector database
  qdrant_storage:
    driver: local
  
  # Persistent storage for Redis (event queue and cache)
  redis_data:
    driver: local

secrets:
  # Docker Secrets for sensitive data
  # More secure than environment variables (not visible in 'docker inspect')
  gemini_api_key:
    file: ./secrets/gemini_api_key.txt

networks:
  # Internal network for service communication
  # Explicit name prevents Docker Compose from prepending project name
  podcast-network:
    name: podcast-network
    driver: bridge

# =================================================================
# USAGE INSTRUCTIONS
# =================================================================
#
# 1. Build and start all services:
#    docker-compose up -d
#
# 2. Start only specific services:
#    docker-compose up -d qdrant rag-service
#
# 3. View logs:
#    docker-compose logs -f
#    docker-compose logs -f rag-service
#
# 4. Stop all services:
#    docker-compose down
#
# 5. Stop and remove volumes (deletes database):
#    docker-compose down -v
#
# 6. Rebuild services after code changes:
#    docker-compose up -d --build
#
# =================================================================
# NOTES
# =================================================================
#
# - The transcription worker requires:
#   - NVIDIA GPU with CUDA support
#   - nvidia-container-toolkit installed on host
#   - Large model files (~10GB) downloaded automatically on first run
#   
#   Run directly on host (optional):
#   conda activate podcast_bot
#   python transcription-service/src/worker_daemon.py
#
# - The RAG service requires Ollama to be running on the host:
#   - Install Ollama: https://ollama.ai/download
#   - Pull required models:
#     ollama pull qwen2.5:7b
#     ollama pull nomic-embed-text
#   - Ollama must be running before starting RAG service
#
# - Shared directories are mounted into containers:
#   - shared/output: Transcription service writes, RAG/Summarization services read (read-only)
#   - shared/summaries: Summarization service writes summaries
#   - shared/config: Transcription API reads/writes configuration
#   - shared/logs: All services can write logs
#
# - Docker Secrets (RECOMMENDED for production):
#   - API keys stored in secrets/ directory (not in environment variables)
#   - More secure: not visible in 'docker inspect' or process listings
#   - Setup: Place your Gemini API key in secrets/gemini_api_key.txt
#   - The secrets/ directory is gitignored to prevent accidental commits
#
# - Development vs Production:
#   - Production (default): Frontend uses built static files, no source code mounted
#   - Development: Use docker-compose.dev.yml for live-reload
#     Command: docker-compose -f docker-compose.yml -f docker-compose.dev.yml up
#
# - Health checks:
#   - Qdrant: http://localhost:6333/dashboard
#   - RAG API: http://localhost:8000/health
#   - RAG Docs: http://localhost:8000/docs
#   - Summarization API: http://localhost:8002/health
#   - Summarization Docs: http://localhost:8002/docs
#   - Frontend: http://localhost:3000
#
# - Environment variables:
#   - Copy .env.example to .env and configure
#   - Most settings have sensible defaults
#   - GEMINI_API_KEY can be set in .env OR in secrets/gemini_api_key.txt (recommended)
#   - Ollama must be installed and running for RAG service
#
# - Volumes:
#   - qdrant_storage: Persists vector database between restarts
#   - To reset database: docker-compose down -v
