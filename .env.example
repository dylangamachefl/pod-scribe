# =================================================================
# PODCAST TRANSCRIBER ENVIRONMENT CONFIGURATION
# =================================================================
# Copy this file to .env and fill in your actual values
# This file contains configuration for all services in the monorepo

# =================================================================
# TRANSCRIPTION SERVICE
# =================================================================
# AI-powered podcast transcription with speaker diarization

# --- Authentication ---
# Required: Hugging Face token for Pyannote speaker diarization
# Get token from: https://huggingface.co/settings/tokens
# Required model access: pyannote/speaker-diarization-3.1
HUGGINGFACE_TOKEN=your_huggingface_token_here

# --- Hardware Configuration ---
# Device for AI models (cuda for NVIDIA GPU, cpu for CPU-only)
DEVICE=cuda

# Compute type for WhisperX (int8 recommended for 8GB VRAM GPUs)
# Options: int8 (fastest, lowest VRAM), float16, float32
COMPUTE_TYPE=int8

# Batch size for transcription (lower for less VRAM, higher for speed)
# Recommended: 4 for RTX 3070 (8GB), 8 for RTX 3080+ (10GB+)
BATCH_SIZE=4

# --- AI Models ---
# WhisperX model for transcription
# Options: tiny, base, small, medium, large-v2, large-v3
# Recommended: large-v2 for best quality (requires 8GB+ VRAM with int8)
WHISPER_MODEL=large-v2

# =================================================================
# RAG SERVICE
# =================================================================
# Semantic search and Q&A over transcripts

# --- API Keys ---
# Required: Google Gemini API key for LLM capabilities
# Get key from: https://makersuite.google.com/app/apikey
GEMINI_API_KEY=your_gemini_api_key_here

# --- Vector Database ---
# Qdrant vector database connection (Docker container)
# Default: http://localhost:6333 if running locally
QDRANT_URL=http://localhost:6333

# Collection name for storing transcript embeddings
QDRANT_COLLECTION_NAME=podcast_transcripts

# --- File Paths ---
# These paths use the new monorepo structure with shared/ directory
# Transcription service outputs to shared/output/, RAG service reads from there

# Path to monitor for new transcripts (auto-ingestion)
# Default: ./shared/output (relative to project root)
TRANSCRIPTION_WATCH_PATH=./shared/output

# Path to save generated summaries
# Default: ./shared/summaries
SUMMARY_OUTPUT_PATH=./shared/summaries

# --- Embedding Configuration ---
# Sentence transformer model for vector embeddings
# Options:
#   - all-MiniLM-L6-v2 (384 dim, fast, decent quality) [RECOMMENDED]
#   - all-mpnet-base-v2 (768 dim, slower, better quality)
#   - multi-qa-MiniLM-L6-cos-v1 (384 dim, optimized for Q&A)
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Embedding vector dimension (must match model output)
EMBEDDING_DIMENSION=384

# --- RAG API Configuration ---
# Port for RAG FastAPI server
RAG_API_PORT=8000

# Frontend URL for CORS (React frontend)
RAG_FRONTEND_URL=http://localhost:3000

# --- Transcription API Configuration ---
# Port for Transcription API server (separate from RAG API)
TRANSCRIPTION_API_PORT=8001

# --- Frontend Configuration ---
# Port for React frontend
FRONTEND_PORT=3000

# API URLs for frontend (Vite environment variables)
VITE_RAG_API_URL=http://localhost:8000
VITE_TRANSCRIPTION_API_URL=http://localhost:8001


# --- Text Processing ---
# Chunking strategy for splitting transcripts
# Chunk size in characters (smaller = more precise, larger = more context)
CHUNK_SIZE=500

# Overlap between chunks (helps maintain context across boundaries)
CHUNK_OVERLAP=100

# --- Retrieval Configuration ---
# Number of most relevant chunks to retrieve for each query
TOP_K_RESULTS=5

# Minimum similarity score to include a chunk (0.0 to 1.0)
# Higher = more strict (only very similar results)
SIMILARITY_THRESHOLD=0.7

# =================================================================
# DEVELOPMENT & TESTING
# =================================================================

# Use mock API responses instead of real Gemini API (for testing)
# Set to 'false' for production
USE_MOCK_API=false

# Enable debug logging (more verbose output)
DEBUG=false

# =================================================================
# OPTIONAL OVERRIDES
# =================================================================
# These have sensible defaults but can be customized

# Output directory for transcripts (auto-created)
# OUTPUT_DIR=./shared/output

# Log directory (auto-created)
# LOG_DIR=./shared/logs

# Temporary directory for downloaded audio files
# TEMP_DIR=./transcription-service/temp

# =================================================================
# NOTES
# =================================================================
# 1. Never commit .env to version control (listed in .gitignore)
# 2. Keep your API keys secure
# 3. The transcription service requires CUDA-capable GPU
# 4. The RAG service requires Docker for Qdrant
# 5. All paths are relative to the project root directory
